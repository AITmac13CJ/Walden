1. 预测

   监控样本为时间序列，通过分析监控项的序列，得到未来一段时间的预测值。

   | 模型                   | 时间开销 | 准确率 | 开源包           |
   | ---------------------- | -------- | ------ | ---------------- |
   | LR(线性回归)           | 少       | 低     | sklearn          |
   | ARIMA                  | 少       | 低     | statsmodels      |
   | 浅层神经网络，回归树等 | 中       | 中     | pybrain, sklearn |
   | LSTM                   | 多       | 高     | tensorflow       |

   预测大体上分为故障预测、容量预测和性能预测。业界基于 RSTM 的一个算法，该算法是基于时序数据预测的一个经典算法。

2. 异常检测

   异常检测是AIOPS最常见的场景，算法也有很多，业界比较流行的比如普通的统计学习方法--3σ原则，它利用检测点偏移量来检测出异常。比如普通的回归方法，用曲线拟合方法来检测新的节点和拟合曲线的偏离程度，甚至有人将CNN和RNN模型应用到异常点的检测。

   异常值本质上是一个数据点。通常，大多数应用程序中的数据是由一个或多个反映系统功能的程序产生的。当底层应用程序以不正常的方式运行时，它会产生异常值。

   通常所说的异常大致分为异常值、波动点和异常时间序列三类。

   ​	a. 异常值（ Outlier)

   ​	b. 波动点（ Change Point )

   ​	c. 异常时间序列（ Anomalous Time-series )

   在监控系统中，主要处理的是时序数据，而时序数据具有一定的特征。

   同比环比预测器
   同比环比是比较常用的异常检测方式，它是将当前时刻数据和前一时刻数据（环比）或者前一天同一时刻数据（同比）比较，超过一定阈值即认为该点异常。

   基线预测器
   同比环比使用历史上的单点数据来预测当前数据，误差比较大。t时刻的监控数据，与 t-1,t-2,…时刻的监控数据存在相关性。同时，与t-k,t-2k,…时刻的数据也存在相关性（k为周期），如果能利用上这些相关数据对t时刻进行预测，预测结果的误差将会更小。

   Holt-Winters预测器
   同比环比预测到基线数据预测，使用的相关数据变多，预测的效果也较好。但是基线数据预测器只使用了周期相关的历史数据，没有使用上同周期相邻时刻的历史数据，相邻时刻的历史数据对于当前时刻的预测影响是比较大的。

   计算序列的周期性数据
   时间序列的周期性数据不需要实时计算，按周期性更新即可，如外卖订单大盘监控，s(t)只需要每天更新一次即可。对于s(t)的计算，可以有多种方法，可以使用上面提到的Holt-Winters按公式计算出时间序列的周期性数据，或直接使用前一天的监控数据作为当天的周期数据（这两种方式都需要对输入序列进行预处理，保证算法的输入序列不含有异常数据）。也可以将历史数据做平均求出基线作为序列的周期性数据。

   残差数据实时预测
   计算出周期数据后，下一个目标就是对残差数据的预测。实际监控数据与周期数据相减得到残差数据，对残差数据做一次滑动平均，预测出下一刻的残差，将该时刻的残差、周期数据相加即可得到该时刻的预测数据。残差序列的长度设为60，即可以得到比较准确的预测效果。

   离散度Filter：根据预测误差曲线离散程度过滤出可能的异常点。一个序列的方差表示该序列离散的程度，方差越大，表明该序列波动越大。如果一个预测误差序列方差比较大，那么我们认为预测误差的报警阈值相对大一些才比较合理。
   阈值Filter：根据误差绝对值是否超过某个阈值过滤出可能的异常点。阈值Filter设计了一个分段阈值函数y=f(x)，对于实际值x和预测值p，只有当|x-p|>f(x)时报警。实际使用中，可以寻找一个对数函数替换分段阈值函数，更易于参数调优。

   无阈值KPI曲线异常识别
   四大黄金指标包括交易量(业务实时产生的交易量)、业务成功率(业务成功量/交易量)、系统成功率(系统成功量/交易量, 业务成功量和系统成功量的区别在于是否明确捕捉到系统异常)、平均时延(交易的平均耗时)。这四大黄金指标都是分钟级数据，这四个指标统计维度不同，波动规律也有所差别，因此需要用不同的算法检测。

   基于LSTM与高斯分布的检测，这个算法主要用于交易量和时延的检测。大部分的曲线突变都能准确检测到，但算法的死角在于小幅度长时间的缓慢变化容易被漏掉。
   基于k-means算法的特征检测，主要用于填补第一种算法的盲区,在交易量缓慢变化的案例效果较好。
   基于概率密度的检测，主要用于业务成功率和系统成功率的曲线，因为成功率曲线的背后隐藏着无数的可能，需要用一个更接近本质的量来衡量异常的程度。
   而以上三种方法都有一个共同的判断原则——少见即异常。在我们确立了无监督为主的大前提下，异常检测的问题转换成了如何衡量当前的情况是否“少见”的问题。
   首先是数据源的异常检测。
   Z-score算法
   Z-score算法，就是每个点减去均价再除方差，衡量计算这个点与整体情况的偏离度，达到一定程度就标记为极度异常数据（不纳入指标统计）。
   用最简单的方法先过滤掉，在正常情况下，z-score能够帮助我们过滤掉更多的异常，而在真正出现故障时，可以减少对合理异常数据的过滤。

   但是这个z-score算法，优点的计算简单，计算成本低，但是缺点是后期人工成本高；比如对于数据滑窗参数要手工调整，同时阈值也需要手工判断，成本较高。同时，算法本身对于异常点突出效果不明显的话，阈值难以取舍。接下来就是来了基于Boxplot箱线图的改良算法。

   Boxplot算法
   该算法核心是基于箱线图算法来改良的，在这个思想里，默认异常数据百分比是比较低且相对稳定的，不过，指标数据一般不是完美的正态分布，比如时延指标是有右偏（偏大）情况，会往高的时延方向偏移，因此，我们在原有的箱线图算法中加了一个重心偏移。同时，我们还发现时延数据不仅有重心偏移，还存在长尾效应，因此我们还加入了长尾修正参数，即：99分位数据减去中间值除上75分位与中间值来衡量这个长尾效应，这样，算法很好地解决了存在重心偏移以及长尾效应的异常数据过滤。

   时间序列分解算法
   数据源的异常检测解决好后，指标的异常检测就有了基础。

   大家经常用到异常检测方法的时间序列分解法，周期项、趋势项、残差项的计算都在其中。从算法表现图上来看，通过周期学习，趋势计算后，原始数据减去周期再减去趋势，就变成了白噪声。通过置信空间的计算，叠加原来计算的周期与趋势，就得到了指标的上下阈值。

   因为用户少，少量用户的异常失败就会导致整个指标下降30%甚至更多，而且每天发生这种下降的随机性很强。

   多工况检测算法
   上面时间序列分解算法所不能适应的场景，就是多工况检测（MRCheck）算法的由来，这个算法外部用的很少，在此分享下，我们通过历史数据的特征进行贡献度识别，其实数据的波动和请求量还有时间是有关系的。因此，如图所示流程，会根据特征（请求量和时间），建立不同的工况（本质是聚类算法），如3~20种工况，然后通过各个点与聚类中心点的距离进行工况划分的评估，确定工况划分的合理性。

   可以这么理解，以前时间序列是只有一种工况的特例，而现在我们通过变成多种工况，重新评估置信空间，异常检测阈值线根据工况变化随之发生变化，很好的解决了原来时间序列分解算法的问题。

   